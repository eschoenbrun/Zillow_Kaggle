{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mca\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fancyimpute import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stevens\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Stevens/Desktop/BIA 686/zillow/bia_686/data/properties_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv('C:/Users/Stevens/Desktop/BIA 686/zillow/bia_686/data/train_2016_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_data = pd.merge(target, df, on=\"parcelid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('C:/Users/Stevens/Desktop/BIA 686/zillow/bia_686/data/properties_2017.csv')\n",
    "target2 = pd.read_csv('C:/Users/Stevens/Desktop/BIA 686/zillow/bia_686/data/train_2017_v2.csv')\n",
    "joined_data2 = pd.merge(target2, df2, on=\"parcelid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    return props, NAlist\n",
    "\n",
    "props, NAlist = reduce_mem_usage(joined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-a87ab93ec988>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#del target_2017\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#del prop_2017\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "del target\n",
    "#del target_2017\n",
    "del df\n",
    "#del prop_2017\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--- Creating two additional columns each for the month and day ---\n",
    "joined_data.transactiondate = pd.to_datetime(joined_data.transactiondate,format='%Y-%m-%d')\n",
    "\n",
    "joined_data['transaction_yr'] = joined_data.transactiondate.dt.weekday.astype(np.int64)\n",
    "joined_data['transaction_mth'] = joined_data.transactiondate.dt.month.astype(np.int64)\n",
    "joined_data['transaction_day_of_wk'] = joined_data.transactiondate.dt.weekday.astype(np.int64)\n",
    "\n",
    "#--- Dropping the 'transactiondate' column now ---\n",
    "joined_data = joined_data.drop('transactiondate', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing rows with a lot of missing columns\n",
    "# df = joined_data.ix[joined_data.isnull().sum(axis=1) < 29, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_cols = ['roomcnt', 'bathroomcnt', 'fullbathcnt', 'bedroomcnt', \n",
    "            'fireplacecnt', 'garagecarcnt','numberofstories', 'poolcnt', \n",
    "            'unitcnt', 'finishedfloor1squarefeet', 'basementsqft', 'calculatedfinishedsquarefeet', \n",
    "            'finishedsquarefeet13', 'finishedsquarefeet6', 'lotsizesquarefeet', 'yardbuildingsqft17', 'yardbuildingsqft26', \n",
    "            'poolsizesum', 'finishedsquarefeet15', 'garagetotalsqft', 'landtaxvaluedollarcnt', \n",
    "            'structuretaxvaluedollarcnt', 'taxamount', 'transaction_day_of_wk','transaction_mth',\n",
    "            'transaction_yr', 'taxdelinquencyyear','yearbuilt','latitude','longitude']\n",
    "num_data = joined_data[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bed, bath and room are the only variables with significant amout of outliers.  \n",
    "outliers = {}\n",
    "for col in num_data.columns:\n",
    "    var = num_data[col].dropna()\n",
    "    index = var[~((var-var.mean()).abs()<2*var.std())]\n",
    "    outliers[col] = index\n",
    "\n",
    "outliers = pd.DataFrame.from_dict(outliers).dropna(how='all')\n",
    "\n",
    "\n",
    "def outliers_iqr(ys):\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    \n",
    "    return np.where((ys > upper_bound) | (ys < lower_bound))\n",
    "\n",
    "out_dict = {}\n",
    "for col in num_data.columns:\n",
    "    outlier = outliers_iqr(num_data[col])\n",
    "    out_dict[col] = outlier\n",
    "    \n",
    "out_dict = dict((k, out_dict[k]) for k in ('bathroomcnt','bedroomcnt','roomcnt'))\n",
    "\n",
    "bath = pd.DataFrame(list(list(out_dict['bathroomcnt'])[0])).reset_index()\n",
    "bed = pd.DataFrame(list(list(out_dict['bedroomcnt'])[0])).reset_index()\n",
    "room = pd.DataFrame(list(list(out_dict['roomcnt'])[0])).reset_index()\n",
    "\n",
    "out_bbb = bath.merge(bed, on=0, how='outer').merge(room, on=0, how='outer')\n",
    "out_bbb.columns = ['index', 'bathroomcnt','bedroomcnt','roomcnt']\n",
    "out_bbb = out_bbb.iloc[:, 1:4]\n",
    "# prob not anomalous: joined_data.loc[[14440, 42387, 60385]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only 443 outliers for bedroom - replace with median\n",
    "bed_ix = (list(list(out_dict['bedroomcnt'])[0]))\n",
    "bed_median = joined_data.iloc[~joined_data.index.isin(bed_ix)].bedroomcnt.median()\n",
    "joined_data.loc[(bed_ix), 'bedroomcnt'] = bed_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in those properties that have a pool with median pool value\n",
    "poolsizesum_median = joined_data.loc[joined_data['poolsizesum'] > 0, 'poolsizesum'].median()\n",
    "joined_data.loc[(joined_data['poolsizesum'].isnull() | \n",
    "                joined_data['poolsizesum'] == 0) & \n",
    "            ((pd.notnull(joined_data['poolcnt'])) |\n",
    "            (pd.notnull(joined_data['pooltypeid10'])) |\n",
    "            (pd.notnull(joined_data['pooltypeid2'])) |\n",
    "            (pd.notnull(joined_data['pooltypeid7']))), 'poolsizesum'] = poolsizesum_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in those properties that have a pool size/type with pool count of 1\n",
    "joined_data.loc[(joined_data['poolcnt'] != 1) & \n",
    "            ((pd.notnull(joined_data['poolsizesum'])) |\n",
    "            (pd.notnull(joined_data['pooltypeid10'])) |\n",
    "            (pd.notnull(joined_data['pooltypeid2'])) |\n",
    "            (pd.notnull(joined_data['pooltypeid7']))), 'poolcnt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill in fireplace count with mode when there is a fireplace flag is true\n",
    "joined_data.loc[(joined_data.fireplaceflag == True) & (joined_data.fireplacecnt.isnull()), 'fireplacecnt'] = joined_data.fireplacecnt.dropna().mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of car garage is more that sqft\n",
    "garage_median = joined_data[(joined_data.garagetotalsqft != 0)].garagetotalsqft.dropna().median()\n",
    "joined_data.loc[(joined_data.garagetotalsqft == 0) & (joined_data.garagecarcnt > 0), 'garagetotalsqft'] = garage_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unitcnt extreme outliers\n",
    "unit_median = joined_data.loc[pd.notnull(joined_data['unitcnt'])]['unitcnt'].median()\n",
    "joined_data.loc[(joined_data['unitcnt'] > 9), 'unitcnt'] = unit_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns missing 99% of data\n",
    "missing_df = joined_data.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df['missing_ratio'] = missing_df['missing_count'] / joined_data.shape[0]\n",
    "missing_df.ix[missing_df['missing_ratio']>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_data_sam = joined_data.sample(frac=.05)\n",
    "train, test = train_test_split(joined_data_sam, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_cols = ['roomcnt', 'bathroomcnt', 'fullbathcnt', 'bedroomcnt', \n",
    "            'fireplacecnt', 'garagecarcnt','numberofstories', 'poolcnt', \n",
    "            'unitcnt', 'finishedfloor1squarefeet', 'basementsqft', 'calculatedfinishedsquarefeet', \n",
    "            'finishedsquarefeet13', 'finishedsquarefeet6', 'lotsizesquarefeet', 'yardbuildingsqft17', 'yardbuildingsqft26', \n",
    "            'poolsizesum', 'finishedsquarefeet15', 'garagetotalsqft', 'landtaxvaluedollarcnt', \n",
    "            'structuretaxvaluedollarcnt', 'taxamount', 'transaction_day_of_wk','transaction_mth',\n",
    "            'transaction_yr', 'taxdelinquencyyear','yearbuilt','latitude','longitude', 'logerror']\n",
    "num_data = train[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['pooltypeid10', 'storytypeid', 'propertylandusetypeid', 'pooltypeid7', 'taxvaluedollarcnt', \n",
    " 'buildingqualitytypeid', 'typeconstructiontypeid', 'airconditioningtypeid', 'hashottuborspa',\n",
    " 'pooltypeid2', 'propertycountylandusecode', 'heatingorsystemtypeid', 'censustractandblock',\n",
    " 'architecturalstyletypeid']\n",
    "cat_data = train[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = num_data.drop('logerror', axis=1).values\n",
    "y_train = num_data['logerror'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar = StandardScaler().fit(X_train)\n",
    "num_data_norm = scalar.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = PCA(n_components=.85, svd_solver='full')\n",
    "num_data_pca = estimator.fit(num_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_plot = np.cumsum(np.round(num_data_pca.explained_variance_ratio_, decimals=4)*100)\n",
    "plt.plot(pca_plot)\n",
    "print(pca_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = num_data_pca.transform(num_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(criterion='mae',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('logerror',axis=1).values\n",
    "X_test = scalar.transform(X_test)\n",
    "X_test = num_data_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = test['logerror'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.094385071764189601"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stevens\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cat_data['hashottuborspa'] = cat_data['hashottuborspa'].apply(lambda x: 1 if x == 'True' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    item for item in cat_cols\n",
    "                    if item not in ['buildingclasstypeid','fireplaceflag','storytypeid']\n",
    "]\n",
    "\n",
    "cat_train = train[cat_cols].copy()\n",
    "for col in cat_cols:\n",
    "    if len(train[col].unique()) == 2:\n",
    "        if cat_train[col].dtype in [np.float32, np.float64,np.int32,np.int64]:\n",
    "            cat_train[col]=cat_train[col].fillna(0)\n",
    "        else:\n",
    "            cat_train[col]=cat_train[col].fillna('no')\n",
    "    else:\n",
    "        cat_train[col]=cat_train[col].fillna(cat_train[col].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    cat_train[col]=cat_train[col].apply(lambda x: str(x))\n",
    "\n",
    "cat_dummies = pd.get_dummies(cat_train[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3611, 6774)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mca = mca.MCA(cat_dummies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
